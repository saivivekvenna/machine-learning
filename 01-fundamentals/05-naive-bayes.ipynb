{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes \n",
    "\n",
    "Suppose you are trying to orginize your email. How would you take the texts and catigorize it? This is a text classification problem.\n",
    "\n",
    "Firstly you want to assemble all the words you want to look out for. Might be the 10,000 most reoccuring words in your inbox. \n",
    "\n",
    "One way to do this is to create a binary feature vector that creates a 1 if a word appears in the email or 0 if not. \n",
    "\n",
    "$x ∈ \\{0,1\\}^n$ with the condition {word i appeares in email}\n",
    "\n",
    "In this example $n$ would be 10,000. \n",
    "\n",
    "**Key Idea:** Assume $ X_i $’s are conditionally independent given $ y $\": This means that once the class $ y $ (e.g., spam or not spam) is known, the features $ X_1, X_2, \\ldots, X_{n} $ (e.g., words in an email) don’t influence each other.\n",
    "\n",
    "$$\\left( \\prod_{i=1}^n p(X_i | y) \\right) p(y)$$\n",
    "\n",
    "This algo has a high bias because it wouldnt take into account the order which the words are on the page. It has a low variance for its abilty to predict well. \n",
    "## Implementation Of Naive Bayes\n",
    "\n",
    "I followed [this video](https://www.youtube.com/watch?v=TLInuAorxqE) to implement as python code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classification accuracy 0.965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayes:\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self._classes = np.unique(y)\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        # calculate mean, var, and prior for each class\n",
    "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._priors = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        for idx, c in enumerate(self._classes):\n",
    "            X_c = X[y == c]\n",
    "            self._mean[idx, :] = X_c.mean(axis=0)\n",
    "            self._var[idx, :] = X_c.var(axis=0)\n",
    "            self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
    "            \n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        # calculate posterior probability for each class\n",
    "        for idx, c in enumerate(self._classes):\n",
    "            prior = np.log(self._priors[idx])\n",
    "            posterior = np.sum(np.log(self._pdf(idx, x)))\n",
    "            posterior = posterior + prior\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        # return class with the highest posterior\n",
    "        return self._classes[np.argmax(posteriors)]\n",
    "\n",
    "    def _pdf(self, class_idx, x):\n",
    "        mean = self._mean[class_idx]\n",
    "        var = self._var[class_idx]\n",
    "        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n",
    "\n",
    "\n",
    "# Testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Imports\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import datasets\n",
    "\n",
    "    def accuracy(y_true, y_pred):\n",
    "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "        return accuracy\n",
    "\n",
    "    X, y = datasets.make_classification(\n",
    "        n_samples=1000, n_features=10, n_classes=2, random_state=123\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=123\n",
    "    )\n",
    "\n",
    "    nb = NaiveBayes()\n",
    "    nb.fit(X_train, y_train)\n",
    "    predictions = nb.predict(X_test)\n",
    "\n",
    "    print(\"Naive Bayes classification accuracy\", accuracy(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlstuff)",
   "language": "python",
   "name": "mlstuff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
