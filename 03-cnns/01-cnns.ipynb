{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "Images can vary due to occlusions, lighting, rotations, and translations; models must be robust to intra-class variations but sensitive to inter-class differences.\n",
    "\n",
    "Manual feature definition (e.g., eyes/nose for faces) is brittle; neural networks learn features hierarchically from data (pixels → edges → complex shapes like eyes).\n",
    "\n",
    "**Limitations of fully connected networks:**\n",
    "Flattening 2D images to 1D vectors loses spatial structure. High parameter count (e.g., 100x100 image → 10,000 inputs, leading to millions of weights).\n",
    "\n",
    "Solution: Connect neurons to local patches of the input to preserve spatial relationships. This is the essence of a CNN. \n",
    "\n",
    "To these small patchs, you apply filters, which extact local features such as edges or shapes.\n",
    "\n",
    "**How Convolution Works:**\n",
    "1. Input: Typically an image, represented as a 2D or 3D tensor. \n",
    "2. Filter: A small matrix (e.g., 3x3 or 5x5) with learnable weights.\n",
    "3. Convolution Operation: The filter slides over the input image with a specified stride (step size), computing a dot product between the filter weights and the local patch at each position. This produces a feature map (or activation map), which highlights regions where the filter’s pattern (e.g., an edge) is present.\n",
    "\n",
    "\n",
    "\n",
    "So a CNN is very simlar to a normal NN but instead of directly applying the weights and bias you are first convulting to a small patch. Then you repeat this step with the patch moved over a little bit. \n",
    "\n",
    "The next step is to take the feature map of that we got from the filter and apply a non-linearlity. One very popular method to do this is the ReLU fuction, which basicly looks pixel by pixel and if its a negative value, it sets it to zero. \n",
    "\n",
    "**Pooling:** Pooling is used to reduce the amount of dimiensions in an image as you go deeper into the network. So what pooling does is instead of convolution where the patches are essentially enlarged, you take the maximum value of a patch and then propagating only the maximums. Another method would be mean pooling where you find the average. \n",
    "\n",
    "Pooling layers reduce the spatial dimensions (height and width) of feature maps while preserving important information.\n",
    "\n",
    "**Global Flattening**:\n",
    "After several iterations of convolution, ReLU and pooling the feature maps are typically flattened or globally pooled and fed into fully connected layers for tasks like classification.\n",
    "- Flattening: A 7x7x512 feature map becomes a 7×7×512 = 25,088-element vector, which is fed into dense layers.\n",
    "- Global Average Pooling: Takes the average of each feature map (e.g., 7x7 → 1 value per channel), producing a 512-element vector. This is more parameter-efficient and common in modern CNNs.\n",
    "\n",
    "**A typical CNN architecture looks like:**\n",
    "$$ \\text{Input} \\rightarrow [\\text{Conv} \\rightarrow \\text{ReLU} \\rightarrow \\text{Pooling}] \\times N \\rightarrow \\text{Flatten/Global Pool} \\rightarrow \\text{FC} \\rightarrow \\text{Output} $$\n",
    "\n",
    "\n",
    "\n",
    "### Maths:\n",
    "\n",
    "Note: True convolution involves flipping the kernel (filter) before sliding it over the input.\n",
    "In practice, CNNs use cross-correlation (no flip), which is mathematically similar but simpler to implement.\n",
    "Cross-Correlation Operation: For a 2D input matrix $ I $ (e.g., an image) and a kernel $ K $ of size $ k \\times k $, the output $ O $ at position $ (i, j) $ is:\n",
    "$$O_{i,j} = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} I_{i+m, j+n} \\cdot K_{m,n}$$\n",
    "This is the dot product of the kernel and the overlapping input patch.\n",
    "To arrive at this: Start with the definition of 2D cross-correlation. Align the kernel's top-left with the input's position $ (i,j) $, multiply element-wise, and sum. No flipping of $ K $.\n",
    "The goal is to extract features like edges or patterns by applying multiple kernels.\n",
    "\n",
    "1. Methods of applying the filter(kernal) in the convolution/\n",
    "**Valid Mode**: No padding; the kernel only slides where it fully overlaps the input.\n",
    "For an input of size $ h \\times w $ and kernel $ k \\times k $:\n",
    "Output size: $ (h - k + 1) \\times (w - k + 1) $.\n",
    "**Full Mode:** Adds zero-padding around the input so the kernel can slide beyond edges, producing a larger output.\n",
    "Padding size: Typically $ \\frac{k-1}{2} $ on each side (for odd $ k $).\n",
    "Output size: $ (h + k - 1) \\times (w + k - 1) $.\n",
    "\n",
    "2. Convolutional Layer: \n",
    "    - Forward pass: \n",
    "        - Input: A 3d Tensor (Image).\n",
    "        - Kernels: Multple 3D Filters\n",
    "        - Computation: $$O[:,:,o] = \\sum_{c=1}^{c_{in}} \\text{cross\\_correlate}(I[:,:,c], K[:,:,c,o]) + b_o$$\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
